{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9da7cbcb-b211-47d7-93f5-987606fa8aa7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:04<00:00,  6.24it/s]\n",
      "100%|██████████| 30/30 [00:05<00:00,  5.44it/s]\n",
      "100%|██████████| 30/30 [00:05<00:00,  5.45it/s]\n",
      "100%|██████████| 30/30 [00:21<00:00,  1.38it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join\n",
    "from scipy.optimize import curve_fit\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "crop='swh'\n",
    "month=[1, 2,10, 11, 12]\n",
    "tpye='Irr'\n",
    "acc='irr'\n",
    "hemisphere='sou'\n",
    "# lat=85;lon=608\n",
    "fp=r'/pb1/home/wanghaiqing@iga.ac.cn/gwsp3'\n",
    "ds = xr.open_dataset(join(fp, f'crop_daily_tavg_{tpye}_daily_{crop}_{hemisphere}_1.nc'),decode_times=False)[f'crop_daily_tavg_{tpye}']\n",
    "time_raw = ds.time.values \n",
    "start_date = pd.Timestamp('1901-01-01')\n",
    "time_index = [start_date + pd.Timedelta(days=int(day)) for day in time_raw]\n",
    "tas1 = ds.assign_coords(time=('time', time_index))\n",
    "tas1=tas1.sel(time=tas1['time.month'].isin(month))\n",
    "ds = xr.open_dataset(join(fp, f'crop_daily_tavg_{tpye}_daily_{crop}_{hemisphere}_2.nc'),decode_times=False)[f'crop_daily_tavg_{tpye}']\n",
    "tas2 = ds.assign_coords(time=('time', time_index))\n",
    "tas2=tas2.sel(time=tas2['time.month'].isin(month))\n",
    "tas=np.zeros_like(tas1.values)\n",
    "tas2.values\n",
    "for i in tqdm(range(30)):\n",
    "    tas[:,i*12:(i+1)*12,:]=tas1[:,i*12:(i+1)*12,:]+tas2[:,i*12:(i+1)*12,:]\n",
    "tas = xr.DataArray(\n",
    "    tas, \n",
    "    coords={\"time\": tas1.time, \"lat\": tas1.lat, \"lon\": tas1.lon}, \n",
    "    dims=[\"time\", \"lat\", \"lon\"],\n",
    "    name=\"tas\"\n",
    ")\n",
    "\n",
    "del tas1, tas2\n",
    "\n",
    "ds = xr.open_dataset(join(fp, f'crop_daily_Precipitation_{tpye}_daily_{crop}_{hemisphere}_1.nc'),decode_times=False)[f'crop_daily_Precipitation_{tpye}']\n",
    "pr1 = ds.assign_coords(time=('time', time_index))\n",
    "pr1=pr1.sel(time=pr1['time.month'].isin(month))*1000\n",
    "ds = xr.open_dataset(join(fp, f'crop_daily_Precipitation_{tpye}_daily_{crop}_{hemisphere}_2.nc'),decode_times=False)[f'crop_daily_Precipitation_{tpye}']\n",
    "pr2 = ds.assign_coords(time=('time', time_index))\n",
    "pr2=pr2.sel(time=pr2['time.month'].isin(month))*1000\n",
    "pr=np.zeros_like(pr1.values)\n",
    "pr2.values\n",
    "for i in tqdm(range(30)):\n",
    "    pr[:,i*12:(i+1)*12,:]=pr1[:,i*12:(i+1)*12,:]+pr2[:,i*12:(i+1)*12,:]\n",
    "pr = xr.DataArray(\n",
    "    pr, \n",
    "    coords={\"time\": pr1.time, \"lat\": pr1.lat, \"lon\": pr1.lon}, \n",
    "    dims=[\"time\", \"lat\", \"lon\"],\n",
    "    name=\"tas\"\n",
    ")\n",
    "del pr1, pr2\n",
    "# ds_eta = xr.open_dataset(join(fp, 'eta_nonIrr_daily_maiz_nor.nc'),decode_times=False).eta_nonIrr \n",
    "# eta = ds_eta[:,lat,lon].assign_coords(time=('time', time_index))\n",
    "# # eta=eta.sel(time=eta['time.month'].isin([5, 6, 7, 8]))*1000\n",
    "# eta=eta.sel(time=eta['time.month'].isin([5, 6, 7, 8,9])).dropna(dim='time', how='any')*1000\n",
    "\n",
    "ds = xr.open_dataset(join(fp, f'ratio_et_{tpye}_daily_{crop}_{hemisphere}_1.nc'),decode_times=False)[f'ratio_et_{tpye}']\n",
    "ratio_et_nonIrr1 = ds.assign_coords(time=('time', time_index))\n",
    "ratio_et_nonIrr1 = ratio_et_nonIrr1.sel(time=ratio_et_nonIrr1['time.month'].isin(month))\n",
    "ds = xr.open_dataset(join(fp, f'ratio_et_{tpye}_daily_{crop}_{hemisphere}_2.nc'),decode_times=False)[f'ratio_et_{tpye}']\n",
    "ratio_et_nonIrr2 = ds.assign_coords(time=('time', time_index))\n",
    "ratio_et_nonIrr2 = ratio_et_nonIrr2.sel(time=ratio_et_nonIrr2['time.month'].isin(month))\n",
    "ratio_et_nonIrr=np.zeros_like(ratio_et_nonIrr1.values)\n",
    "ratio_et_nonIrr2.values\n",
    "for i in tqdm(range(30)):\n",
    "    ratio_et_nonIrr[:,i*12:(i+1)*12,:]=ratio_et_nonIrr1[:,i*12:(i+1)*12,:]+ratio_et_nonIrr2[:,i*12:(i+1)*12,:]\n",
    "ratio_et_nonIrr = xr.DataArray(\n",
    "    ratio_et_nonIrr, \n",
    "    coords={\"time\": ratio_et_nonIrr1.time, \"lat\": ratio_et_nonIrr1.lat, \"lon\": ratio_et_nonIrr1.lon}, \n",
    "    dims=[\"time\", \"lat\", \"lon\"],\n",
    "    name=\"tas\"\n",
    ")\n",
    "del ratio_et_nonIrr2,ratio_et_nonIrr1\n",
    "frac_path=r'/pb1/home/wanghaiqing@iga.ac.cn/crop_fraction'\n",
    "frac=xr.open_dataset(join(frac_path,f'{crop}_{hemisphere}_{acc}.nc')).__xarray_dataarray_variable__\n",
    "frac=frac.interp(lat=ds.lat,lon=ds.lon)\n",
    "# frac2=xr.open_dataset(join(frac_path,f'{crop}_{hemisphere}_{acc}.nc')).__xarray_dataarray_variable__.interp(lat=ds.lat,lon=ds.lon)\n",
    "\n",
    "ds = xr.open_dataset(join(fp, f'PotET_crop_{tpye}_daily_{crop}_{hemisphere}_1.nc'),decode_times=False)[f'PotET_crop_{tpye}']\n",
    "pet1 = ds.assign_coords(time=('time', time_index))\n",
    "pet1=pet1.sel(time=pet1['time.month'].isin(month))*1000\n",
    "ds = xr.open_dataset(join(fp, f'PotET_crop_{tpye}_daily_{crop}_{hemisphere}_2.nc'),decode_times=False)[f'PotET_crop_{tpye}']\n",
    "pet2 = ds.assign_coords(time=('time', time_index))\n",
    "pet2=pet2.sel(time=pet2['time.month'].isin(month))*1000\n",
    "pet=np.zeros_like(pet1.values)\n",
    "pet2.values\n",
    "for i in tqdm(range(30)):\n",
    "    pet[:,i*12:(i+1)*12,:]=(pet1[:,i*12:(i+1)*12,:]+pet2[:,i*12:(i+1)*12,:])/frac[i*12:(i+1)*12,:].values\n",
    "pet = xr.DataArray(\n",
    "    pet, \n",
    "    coords={\"time\": pet1.time, \"lat\": pet1.lat, \"lon\": pet1.lon}, \n",
    "    dims=[\"time\", \"lat\", \"lon\"],\n",
    "    name=\"tas\"\n",
    ")\n",
    "del pet1,pet2,ds\n",
    "\n",
    "# # ds_yr = xr.open_dataset(join(r'F:\\CWatM\\cwatm_output\\global_future\\GWSP3_W5E5', 'ky_ratio_et_nonIrr_daily_maiz_nor.nc'),decode_times=False).ky_ratio_et_nonIrr\n",
    "# # yr = ds_yr[:,lat,lon].assign_coords(time=('time', time_index))\n",
    "# # # pet=pet.sel(time=pet['time.month'].isin([5, 6, 7, 8]))*1000\n",
    "# # yr=yr.sel(time=yr['time.month'].isin([5, 6, 7, 8,9])).dropna(dim='time', how='any')\n",
    "# # pet=eta/ratio_et_nonIrr\n",
    "dr=(pr-pet)\n",
    "del pet\n",
    "dr_min=dr.min(dim='time')\n",
    "dr_max=dr.max(dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71052ad4-78ac-49c5-9311-09a6af69d39c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]/tmp/ipykernel_200540/4159160865.py:15: RuntimeWarning: All-NaN axis encountered\n",
      "  if np.isnan(np.nanmax(ratio_et_nonIrr[0, ii*key:(ii + 1) * key, :])) or np.nanmax(ratio_et_nonIrr[0, ii*key:(ii + 1) * key, :]) == 0:\n",
      "/usr/lib/python3/dist-packages/numpy/lib/nanfunctions.py:1577: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "\n",
      "  0%|          | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      " 60%|██████    | 18/30 [01:10<00:46,  3.91s/it]\n",
      "  0%|          | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      " 63%|██████▎   | 19/30 [02:20<01:36,  8.75s/it]\n",
      "  0%|          | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      " 67%|██████▋   | 20/30 [03:28<02:23, 14.38s/it]\n",
      "  0%|          | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      " 70%|███████   | 21/30 [04:43<03:14, 21.64s/it]\n",
      "  0%|          | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      " 73%|███████▎  | 22/30 [05:58<03:55, 29.40s/it]\n",
      "  0%|          | 0/12 [00:00<?, ?it/s]\u001b[A\n",
      " 25%|██▌       | 3/12 [00:02<00:07,  1.19it/s]\u001b[A\n",
      "100%|██████████| 30/30 [07:13<00:00, 14.44s/it][A\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import xarray as xr  # 确保已经导入xarray\n",
    "\n",
    "latitudes = dr.coords['lat']\n",
    "longitudes = dr.coords['lon']\n",
    "bins = np.arange(0, 100.1, 0.1)\n",
    "\n",
    "# 创建一个与 dr 相同形状的二维数组\n",
    "shape = dr[0].shape  # 获取 dr 的形状\n",
    "drought = np.full(shape, np.nan)  # 第一个变量，初始化为 NaN\n",
    "flood = np.full(shape, np.nan)  # 第二个变量，初始化为 NaN\n",
    "key=12\n",
    "for ii in tqdm(range(30)):\n",
    "    if np.isnan(np.nanmax(ratio_et_nonIrr[0, ii*key:(ii + 1) * key, :])) or np.nanmax(ratio_et_nonIrr[0, ii*key:(ii + 1) * key, :]) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        rat = ratio_et_nonIrr[:, ii*key:(ii + 1) * key, :]\n",
    "        \n",
    "        dr_idx = 100 * (dr[:, ii*key:(ii + 1) * key, :] - dr_min[ii*key:(ii + 1) * key, :]) / (dr_max[ii*key:(ii + 1) * key, :] - dr_min[ii*key:(ii + 1) * key, :])\n",
    "        # dr_idx = dr[:, ii*30:(ii + 1) * 30, :] - dr_min[ii*30:(ii + 1) * 30, :]\n",
    "        bins = np.arange(0, 100 + 1, 1)  # 以1为间隔划分区间\n",
    "        means = np.full([len(bins) - 1, len(dr_idx.lat), len(dr_idx.lon)], np.nan) \n",
    "        dr_idx_flat = dr_idx.values.flatten()\n",
    "        rat_flat = rat.values.flatten()\n",
    "\n",
    "        for i in range(len(bins) - 1):\n",
    "            # 筛选出当前区间的数据\n",
    "            mask = (dr_idx_flat >= bins[i]) & (dr_idx_flat < bins[i + 1])\n",
    "            rat_in_bin = np.where(mask, rat_flat, np.nan).reshape(rat.shape)\n",
    "\n",
    "            # 使用布尔数组进行索引\n",
    "            masked_rat_da = xr.DataArray(\n",
    "                rat_in_bin,\n",
    "                dims=rat.dims,\n",
    "                coords=rat.coords\n",
    "            )\n",
    "\n",
    "            # 计算均值\n",
    "            means[i] = masked_rat_da.quantile(0.95, dim=\"time\", skipna=True) * np.sum((rat_in_bin > 0), axis=0) / 100\n",
    "\n",
    "        for la in tqdm(range(len(dr_idx.lat)),leave=False):\n",
    "            for lo in range(len(dr_idx.lon)):\n",
    "                if np.all(np.isnan(means[:, la, lo])):  # 检查所有均值是否为 NaN\n",
    "                    continue\n",
    "                \n",
    "                d = []\n",
    "                f = []\n",
    "\n",
    "                mean_rat = np.nanmean(rat[:, la, lo])  # 计算有效的均值\n",
    "                for i in range(1, len(means[:, la, lo])):  # 从1开始以便可以访问means[i-1]\n",
    "                    if not np.isnan(means[i, la, lo]) and not np.isnan(means[i - 1, la, lo]):  # 确保当前和上一个均值不为 NaN\n",
    "                        if means[i, la, lo] > mean_rat and bins[i - 1] < 20 and means[i - 1, la, lo] < mean_rat:\n",
    "                            d.append(bins[i - 1] + 0.5)\n",
    "                        if means[i, la, lo] < mean_rat and bins[i - 1] > 20 and means[i - 1, la, lo] > mean_rat:\n",
    "                            f.append(bins[i - 1] + 0.5)\n",
    "                \n",
    "                drought[ii * key + la, lo] = np.min(d) if d else np.nan\n",
    "                flood[ii * key + la, lo] = np.max(f) if f else np.nan\n",
    "result = xr.Dataset({\n",
    "    'drought': (( 'lat', 'lon'), drought),\n",
    "    'flood': (( 'lat', 'lon'), flood),\n",
    "}, coords={\n",
    "    # 'time': dr.coords['time'],\n",
    "    'lat': dr.lat,\n",
    "    'lon': dr.lon\n",
    "})\n",
    "result.to_netcdf(join(r'/pb1/home/wanghaiqing@iga.ac.cn/results',f'{crop}_{hemisphere}_{acc}_threshold.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2616c5c-9cf6-415c-8792-d10ed272c9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 9/12 [00:13<00:05,  1.71s/it]/tmp/ipykernel_200540/2120903033.py:14: RuntimeWarning: All-NaN axis encountered\n",
      "  if np.isnan(np.nanmax(ratio_et_nonIrr[0, ii*key:(ii + 1) * key, :])) or np.nanmax(ratio_et_nonIrr[0, ii*key:(ii + 1) * key, :]) == 0:\n",
      "100%|██████████| 12/12 [00:13<00:00,  1.14s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import xarray as xr \n",
    "\n",
    "shape = dr[0].shape \n",
    "drought_tas = np.full(shape, np.nan)  \n",
    "drought_pr = np.full(shape, np.nan)  \n",
    "flood_tas = np.full(shape, np.nan)  \n",
    "flood_pr = np.full(shape, np.nan)  \n",
    "drought=xr.open_dataset(join(r'/pb1/home/wanghaiqing@iga.ac.cn/results',f'{crop}_{hemisphere}_{acc}_threshold.nc')).drought\n",
    "flood=xr.open_dataset(join(r'/pb1/home/wanghaiqing@iga.ac.cn/results',f'{crop}_{hemisphere}_{acc}_threshold.nc')).flood\n",
    "key=30\n",
    "for ii in tqdm(range(12)):\n",
    "    if np.isnan(np.nanmax(ratio_et_nonIrr[0, ii*key:(ii + 1) * key, :])) or np.nanmax(ratio_et_nonIrr[0, ii*key:(ii + 1) * key, :]) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        pr_idx = pr[:, ii*key:(ii + 1) * key, :]\n",
    "        tas_idx = tas[:, ii*key:(ii + 1) * key, :]\n",
    "        flood_idx= flood[ ii*key:(ii + 1) * key, :]\n",
    "        drought_idx= drought[ ii*key:(ii + 1) * key, :]\n",
    "        dr_idx = 100 * (dr[:, ii*key:(ii + 1) * key, :] - dr_min[ii*key:(ii + 1) * key, :]) / (dr_max[ii*key:(ii + 1) * key, :] - dr_min[ii*key:(ii + 1) * key, :])\n",
    "        # dr_idx_mm.isel(time=(flood_idx.where(~np.isnan(flood_idx), np.inf)).argmin(dim='time'))\n",
    "        flood_tas[ii*key:(ii + 1) * key, :] = (tas_idx.where((dr_idx >= flood_idx))).mean(dim='time')\n",
    "        flood_pr[ii*key:(ii + 1) * key, :] = (pr_idx.where((dr_idx >= flood_idx))).mean(dim='time')\n",
    "        drought_tas[ii*key:(ii + 1) * key, :] = (tas_idx.where((dr_idx <= drought_idx))).mean(dim='time')\n",
    "        drought_pr[ii*key:(ii + 1) * key, :] = (pr_idx.where((dr_idx <= drought_idx))).mean(dim='time')\n",
    "result = xr.Dataset({\n",
    "    'drought_tas': (( 'lat', 'lon'), drought_tas),\n",
    "    'drought_pr': (( 'lat', 'lon'), drought_pr),\n",
    "    'flood_pr': (( 'lat', 'lon'), flood_pr),\n",
    "    'flood_tas': (( 'lat', 'lon'), flood_tas),\n",
    "}, coords={\n",
    "    # 'time': dr.coords['time'],\n",
    "    'lat': dr.lat,\n",
    "    'lon': dr.lon\n",
    "})\n",
    "result.to_netcdf(join(r'/pb1/home/wanghaiqing@iga.ac.cn/results',f'{crop}_{hemisphere}_{acc}_threshold_climate.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "358d041e-0d8c-4bda-8230-ccfb48c5953e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 9/12 [00:09<00:03,  1.26s/it]/tmp/ipykernel_200540/3819057257.py:13: RuntimeWarning: All-NaN axis encountered\n",
      "  if np.isnan(np.nanmax(ratio_et_nonIrr[0, ii*key:(ii + 1) * key, :])) or np.nanmax(ratio_et_nonIrr[0, ii*key:(ii + 1) * key, :]) == 0:\n",
      "100%|██████████| 12/12 [00:09<00:00,  1.23it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import xarray as xr  # 确保已经导入xarray\n",
    "\n",
    "# 创建一个与 dr 相同形状的二维数组\n",
    "shape = dr[0].shape  # 获取 dr 的形状\n",
    "drought_mm = np.full(shape, np.nan)  # 第一个变量，初始化为 NaN\n",
    "flood_mm = np.full(shape, np.nan)  # 第二个变量，初始化为 NaN\n",
    "drought=xr.open_dataset(join(r'/pb1/home/wanghaiqing@iga.ac.cn/results',f'{crop}_{hemisphere}_{acc}_threshold.nc')).drought\n",
    "flood=xr.open_dataset(join(r'/pb1/home/wanghaiqing@iga.ac.cn/results',f'{crop}_{hemisphere}_{acc}_threshold.nc')).flood\n",
    "key=30\n",
    "for ii in tqdm(range(12)):\n",
    "    if np.isnan(np.nanmax(ratio_et_nonIrr[0, ii*key:(ii + 1) * key, :])) or np.nanmax(ratio_et_nonIrr[0, ii*key:(ii + 1) * key, :]) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        \n",
    "        dr_idx_mm = dr[:, ii*key:(ii + 1) * key, :] - dr_min[ii*key:(ii + 1) * key, :]\n",
    "        dr_idx = 100 * (dr[:, ii*key:(ii + 1) * key, :] - dr_min[ii*key:(ii + 1) * key, :]) / (dr_max[ii*key:(ii + 1) * key, :] - dr_min[ii*key:(ii + 1) * key, :])\n",
    "        flood_idx= np.abs(dr_idx-flood[ ii*key:(ii + 1) * key, :])\n",
    "        drought_idx= np.abs(dr_idx-drought[ ii*key:(ii + 1) * key, :])\n",
    "        \n",
    "        flood_mm[ii*key:(ii + 1) * key, :] = dr_idx_mm.isel(time=(flood_idx.where(~np.isnan(flood_idx), np.inf)).argmin(dim='time'))\n",
    "        drought_mm[ii*key:(ii + 1) * key, :] = dr_idx_mm.isel(time=(drought_idx.where(~np.isnan(drought_idx), np.inf)).argmin(dim='time'))\n",
    "flood_mm=np.where(flood>0,flood_mm,np.nan)\n",
    "drought_mm=np.where(flood>0,drought_mm,np.nan)\n",
    "result = xr.Dataset({\n",
    "    'flood_mm': (( 'lat', 'lon'), flood_mm),\n",
    "    'drought_mm': (( 'lat', 'lon'), drought_mm),\n",
    "}, coords={\n",
    "    # 'time': dr.coords['time'],\n",
    "    'lat': dr.lat,\n",
    "    'lon': dr.lon\n",
    "})\n",
    "result.to_netcdf(join(r'/pb1/home/wanghaiqing@iga.ac.cn/results',f'{crop}_{hemisphere}_{acc}_threshold_mm.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8563666-ced0-4c62-998e-a6e4906b35ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 9/12 [00:10<00:04,  1.39s/it]/tmp/ipykernel_200540/1614313395.py:19: RuntimeWarning: All-NaN axis encountered\n",
      "  if np.isnan(np.nanmax(ratio_et_nonIrr[0, ii*key:(ii + 1) * key, :])) or np.nanmax(ratio_et_nonIrr[0, ii*key:(ii + 1) * key, :]) == 0:\n",
      "100%|██████████| 12/12 [00:10<00:00,  1.11it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import xarray as xr  # 确保已经导入xarray\n",
    "\n",
    "latitudes = dr.coords['lat']\n",
    "longitudes = dr.coords['lon']\n",
    "bins = np.arange(0, 100.1, 0.1)\n",
    "\n",
    "# 创建一个与 dr 相同形状的二维数组\n",
    "shape = dr[0].shape  # 获取 dr 的形状\n",
    "drought_tas = np.full(shape, np.nan)  # 第一个变量，初始化为 NaN\n",
    "drought_pr = np.full(shape, np.nan)  # 第一个变量，初始化为 NaN\n",
    "flood_tas = np.full(shape, np.nan)  # 第一个变量，初始化为 NaN\n",
    "flood_pr = np.full(shape, np.nan)  # 第一个变量，初始化为 NaN\n",
    "drought=xr.open_dataset(join(r'/pb1/home/wanghaiqing@iga.ac.cn/results',f'{crop}_{hemisphere}_{acc}_threshold.nc')).drought\n",
    "flood=xr.open_dataset(join(r'/pb1/home/wanghaiqing@iga.ac.cn/results',f'{crop}_{hemisphere}_{acc}_threshold.nc')).flood\n",
    "key=30\n",
    "for ii in tqdm(range(12)):\n",
    "    if np.isnan(np.nanmax(ratio_et_nonIrr[0, ii*key:(ii + 1) * key, :])) or np.nanmax(ratio_et_nonIrr[0, ii*key:(ii + 1) * key, :]) == 0:\n",
    "        continue\n",
    "    else:\n",
    "        pr_idx = pr[:, ii*key:(ii + 1) * key, :]\n",
    "        tas_idx = tas[:, ii*key:(ii + 1) * key, :]\n",
    "        flood_idx= flood[ ii*key:(ii + 1) * key, :]\n",
    "        drought_idx= drought[ ii*key:(ii + 1) * key, :]\n",
    "        dr_idx = 100 * (dr[:, ii*key:(ii + 1) * key, :] - dr_min[ii*key:(ii + 1) * key, :]) /\\\n",
    "        (dr_max[ii*key:(ii + 1) * key, :] - dr_min[ii*key:(ii + 1) * key, :])\n",
    "        \n",
    "        flood_tas[ii*key:(ii + 1) * key, :] = (tas_idx.where((dr_idx >= flood_idx))).sum(dim='time')\n",
    "        flood_pr[ii*key:(ii + 1) * key, :] = (pr_idx.where((dr_idx >= flood_idx))).sum(dim='time')\n",
    "        drought_tas[ii*key:(ii + 1) * key, :] = (tas_idx.where((dr_idx <= drought_idx))).sum(dim='time')\n",
    "        drought_pr[ii*key:(ii + 1) * key, :] = (pr_idx.where((dr_idx <= drought_idx))).sum(dim='time')\n",
    "result = xr.Dataset({\n",
    "    'drought_tas': (( 'lat', 'lon'), drought_tas),\n",
    "    'drought_pr': (( 'lat', 'lon'), drought_pr),\n",
    "    'flood_pr': (( 'lat', 'lon'), flood_pr),\n",
    "    'flood_tas': (( 'lat', 'lon'), flood_tas),\n",
    "}, coords={\n",
    "    # 'time': dr.coords['time'],\n",
    "    'lat': dr.lat,\n",
    "    'lon': dr.lon\n",
    "})\n",
    "result.to_netcdf(join(r'/pb1/home/wanghaiqing@iga.ac.cn/results',f'{crop}_{hemisphere}_{acc}_threshold_climate_accrue.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9a9fa8-29cd-4f4e-8f47-5b6d491cb5a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26bee61e-a0d7-4c74-9177-d58e2f9c7f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:04<00:00,  6.32it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join\n",
    "from scipy.optimize import curve_fit\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "crop='maiz'\n",
    "month=[1, 2,3, 11, 12]\n",
    "tpye='nonIrr'\n",
    "acc='rf'\n",
    "hemisphere='sou'\n",
    "# lat=85;lon=608\n",
    "fp=r'/pb1/home/wanghaiqing@iga.ac.cn/gwsp3'\n",
    "\n",
    "\n",
    "ds = xr.open_dataset(join(fp, f'ratio_et_{tpye}_daily_{crop}_{hemisphere}_1.nc'),decode_times=False)[f'ratio_et_{tpye}']\n",
    "time_raw = ds.time.values \n",
    "start_date = pd.Timestamp('1901-01-01')\n",
    "time_index = [start_date + pd.Timedelta(days=int(day)) for day in time_raw]\n",
    "ratio_et_nonIrr1 = ds.assign_coords(time=('time', time_index))\n",
    "ratio_et_nonIrr1 = ratio_et_nonIrr1.sel(time=ratio_et_nonIrr1['time.month'].isin(month))\n",
    "ds = xr.open_dataset(join(fp, f'ratio_et_{tpye}_daily_{crop}_{hemisphere}_2.nc'),decode_times=False)[f'ratio_et_{tpye}']\n",
    "ratio_et_nonIrr2 = ds.assign_coords(time=('time', time_index))\n",
    "ratio_et_nonIrr2 = ratio_et_nonIrr2.sel(time=ratio_et_nonIrr2['time.month'].isin(month))\n",
    "ratio_et_nonIrr=np.zeros_like(ratio_et_nonIrr1.values)\n",
    "ratio_et_nonIrr2.values\n",
    "for i in tqdm(range(30)):\n",
    "    ratio_et_nonIrr[:,i*12:(i+1)*12,:]=ratio_et_nonIrr1[:,i*12:(i+1)*12,:]+ratio_et_nonIrr2[:,i*12:(i+1)*12,:]\n",
    "ratio_et_nonIrr = xr.DataArray(\n",
    "    ratio_et_nonIrr, \n",
    "    coords={\"time\": ratio_et_nonIrr1.time, \"lat\": ratio_et_nonIrr1.lat, \"lon\": ratio_et_nonIrr1.lon}, \n",
    "    dims=[\"time\", \"lat\", \"lon\"],\n",
    "    name=\"tas\"\n",
    ")\n",
    "del ratio_et_nonIrr2,ratio_et_nonIrr1\n",
    "ratio_et_nonIrr.mean(dim='time').to_netcdf(join(r'/pb1/home/wanghaiqing@iga.ac.cn/future',f'{crop}_{hemisphere}_{acc}_ration_mean.nc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c9873d-b0b1-4ac2-9b96-786b1023e781",
   "metadata": {},
   "source": [
    "### frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dee53cf2-528b-4a4b-95c5-1ef9d53c487a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:08<00:00,  3.46it/s]\n",
      "100%|██████████| 30/30 [00:38<00:00,  1.29s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join\n",
    "from scipy.optimize import curve_fit\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "crop='wwh'\n",
    "month=[1,2,3,4,5,10,11,12]\n",
    "tpye='nonIrr'\n",
    "acc='rf'\n",
    "hemisphere='nor'\n",
    "# lat=85;lon=608\n",
    "fp=r'/pb1/home/wanghaiqing@iga.ac.cn/gwsp3'\n",
    "ds = xr.open_dataset(join(fp, f'crop_daily_Precipitation_{tpye}_daily_{crop}_{hemisphere}_1.nc'),decode_times=False)[f'crop_daily_Precipitation_{tpye}']\n",
    "time_raw = ds.time.values \n",
    "start_date = pd.Timestamp('1901-01-01')\n",
    "time_index = [start_date + pd.Timedelta(days=int(day)) for day in time_raw]\n",
    "pr1 = ds.assign_coords(time=('time', time_index))\n",
    "pr1=pr1.sel(time=pr1['time.month'].isin(month))*1000\n",
    "ds = xr.open_dataset(join(fp, f'crop_daily_Precipitation_{tpye}_daily_{crop}_{hemisphere}_2.nc'),decode_times=False)[f'crop_daily_Precipitation_{tpye}']\n",
    "pr2 = ds.assign_coords(time=('time', time_index))\n",
    "pr2=pr2.sel(time=pr2['time.month'].isin(month))*1000\n",
    "pr=np.zeros_like(pr1.values)\n",
    "pr2.values\n",
    "for i in tqdm(range(30)):\n",
    "    pr[:,i*12:(i+1)*12,:]=pr1[:,i*12:(i+1)*12,:]+pr2[:,i*12:(i+1)*12,:]\n",
    "pr = xr.DataArray(\n",
    "    pr, \n",
    "    coords={\"time\": pr1.time, \"lat\": pr1.lat, \"lon\": pr1.lon}, \n",
    "    dims=[\"time\", \"lat\", \"lon\"],\n",
    "    name=\"tas\"\n",
    ")\n",
    "del pr1, pr2\n",
    "\n",
    "frac_path=r'/pb1/home/wanghaiqing@iga.ac.cn/crop_fraction'\n",
    "frac=xr.open_dataset(join(frac_path,f'{crop}_{hemisphere}_{acc}.nc')).__xarray_dataarray_variable__\n",
    "frac=frac.interp(lat=ds.lat,lon=ds.lon)\n",
    "# frac2=xr.open_dataset(join(frac_path,f'{crop}_{hemisphere}_{acc}.nc')).__xarray_dataarray_variable__.interp(lat=ds.lat,lon=ds.lon)\n",
    "\n",
    "ds = xr.open_dataset(join(fp, f'PotET_crop_{tpye}_daily_{crop}_{hemisphere}_1.nc'),decode_times=False)[f'PotET_crop_{tpye}']\n",
    "pet1 = ds.assign_coords(time=('time', time_index))\n",
    "pet1=pet1.sel(time=pet1['time.month'].isin(month))*1000\n",
    "ds = xr.open_dataset(join(fp, f'PotET_crop_{tpye}_daily_{crop}_{hemisphere}_2.nc'),decode_times=False)[f'PotET_crop_{tpye}']\n",
    "pet2 = ds.assign_coords(time=('time', time_index))\n",
    "pet2=pet2.sel(time=pet2['time.month'].isin(month))*1000\n",
    "pet=np.zeros_like(pet1.values)\n",
    "pet2.values\n",
    "for i in tqdm(range(30)):\n",
    "    pet[:,i*12:(i+1)*12,:]=(pet1[:,i*12:(i+1)*12,:]+pet2[:,i*12:(i+1)*12,:])/frac[i*12:(i+1)*12,:].values\n",
    "pet = xr.DataArray(\n",
    "    pet, \n",
    "    coords={\"time\": pet1.time, \"lat\": pet1.lat, \"lon\": pet1.lon}, \n",
    "    dims=[\"time\", \"lat\", \"lon\"],\n",
    "    name=\"tas\"\n",
    ")\n",
    "del pet1,pet2,ds\n",
    "\n",
    "dr=(pr-pet)\n",
    "del pet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc614753-53e1-4265-aaf2-184b87ef6865",
   "metadata": {},
   "outputs": [],
   "source": [
    "drought=xr.open_dataset(join(r'/pb1/home/wanghaiqing@iga.ac.cn/results',f'{crop}_{hemisphere}_{acc}_threshold_mm.nc')).drought_mm\n",
    "flood=xr.open_dataset(join(r'/pb1/home/wanghaiqing@iga.ac.cn/results',f'{crop}_{hemisphere}_{acc}_threshold_mm.nc')).flood_mm\n",
    "\n",
    "condition = dr >= flood\n",
    "count_flood = np.sum(condition, axis=0)\n",
    "condition = dr <= drought\n",
    "count_drought = np.sum(condition, axis=0)\n",
    "result = xr.Dataset({\n",
    "    'count_drought': (( 'lat', 'lon'), count_drought.values),\n",
    "    'count_flood': (( 'lat', 'lon'), count_flood.values),\n",
    "}, coords={\n",
    "    # 'time': dr.coords['time'],\n",
    "    'lat': dr.lat,\n",
    "    'lon': dr.lon\n",
    "})\n",
    "result.to_netcdf(join(r'/pb1/home/wanghaiqing@iga.ac.cn/results',f'{crop}_{hemisphere}_{acc}_threshold_climate_frequency.nc'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
